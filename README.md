## Description

Computer Vision offers new tools that can add improvements and more precise analysis and refereeing to professional sports, with methods such as Pose Estimation and automatic action recognition. This project's objective is that from an exercise video uploaded to the web by the user, the developed tool is capable of identifying the exercise and counting the repetitions made. To recognize the user's action, a LSTM Network is utilized, trained by Meta's Sapiens Pose Estimation model. For repetition counting, YOLOv11 Pose Estimation is used, along with an homography transformation to adapt the camera's angle. The tool is accessible through a browser, and has been developed using a React frontend environment and a backend API FastAPI. The project's main feature is its robustness to the camera angle variation, that allows for an accurate counting with high tolerance to variations introduced by the user in the input video.

La VisiÃ³ per Computador ofereix noves eines que poden aportar millores i mÃ©s precisiÃ³ d'anÃ lisi i arbitratge als esports professionals, amb mÃ¨todes com l'estimaciÃ³ de pose i el reconeixement automÃ tic d'accions. L'objectiu en aquest projecte Ã©s el d'a partir d'un vÃ­deo d'exercici pujat a la web per l'usuari, l'eina desenvolupada sigui capaÃ§ de identificar l'exercici i comptar les repeticions que es realitzen. Per a reconÃ¨ixer l'acciÃ³ de l'usuari, s'utilitza una xarxa LSTM, entrenada amb el model Sapiens d'estimaciÃ³ de pose de Meta. Per al comptatge de repeticions s'utilitza EstimaciÃ³ de Pose amb YOLOv11 i una transformaciÃ³ per homografia per corregir la perspectiva de la cÃ mera. La eina Ã©s accessible a travÃ©s de un navegador, i aquesta ha estat desenvolupada en un entorn frontend React amb una API backend FastAPI. La caracterÃ­stica principal en aquesta eina Ã©s la seva robustesa a la variaciÃ³ d'angle de gravaciÃ³, que permet un comptatge precÃ­s amb una tolerÃ ncia gran a les variacions introduÃ¯des per l'usuari al vÃ­deo d'entrada.

<p align="center">
<img src="documents/Poster_Joan_Lara_TFG_RepCount.png" width="750">
</p>

<p align="center">
<img src="repCount_code/frontend_repCount/src/assets/train_pull_up_001.gif" width="500">
</p>

<p align="center">
<img src="repCount_code/frontend_repCount/src/assets/video_example.gif" width="500">
</p>

<p align="center">
<img src="repCount_code/frontend_repCount/src/assets/graph_example.jpg" width="500">
</p>

## Installation

```
git clone https://github.com/Yolopowah03/RepCount.git
cd RepCount
git lfs pull
```

### Backend

```
conda create -n python=3.10 --name repcount
conda activate repcount

pip install fastapi "uvicorn[standard]"
pip install uvicorn apscheduler pydantic[email] passlib python-jose python-multipart ultralytics argon2-cffi
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
```

### Frontend

```
conda create -n python=3.10 --name repcount_frontend
conda activate repcount_frontend

conda install nodejs=20 -c conda-forge -y

cd repCount_code/frontend_repCount
npm install
```

## Initialization

### Backend

```
python -m uvicorn repCount_code.backend_repCount.app.main:app --host=your_host1 --port=your_port1
```

### Frontend

```
cd repCount_code/frontend_repCount
npm run dev -- --port your_port2 --host
```

When using different your_host1 and your_port1, they must be updated in the frontend calls to the backend in /repCount_code/backend_repCount/app/main.py and in the .tsx files under /repCount_code/frontend_repCount/src

## ğŸ“ Project structure

The main pipeline of the project can be found at ./repCount_code/repCount/repCount_YOLO11_web.py

```
.
â”œâ”€â”€ documents # Paper, presentation and poster in PDF format with all submitted versions
â”œâ”€â”€ exercise_dataset_seg # Dataset for training and testing YOLO11seg mask segmentation model
â”œâ”€â”€ LSTM_dataset # Dataset for training and testing LSTM exercise classification model
â”œâ”€â”€ models_exercise_seg # Trained YOLO11seg mask segmentation models
â”œâ”€â”€ models_LSTM # Trained LSTM models for exercise classification
â”œâ”€â”€ models_YOLO11_pose # Trained YOLO11pose pose extraction models
â””â”€â”€ repCount_code
    â”œâ”€â”€ backend_repCount
    â”‚   â”œâ”€â”€ app
    â”‚   â”‚  â”œâ”€â”€ core
    â”‚   â”‚  â”‚   â””â”€â”€ security.py # Backend web user session security functions
    â”‚   â”‚  â”œâ”€â”€ models
    â”‚   â”‚  â”‚   â”‚â”€â”€ schema.py # Model classes for backend web requests and responses
    â”‚   â”‚  â”‚   â””â”€â”€ user_model.py # Database classes for user management
    â”‚   â”‚  â”‚â”€â”€ routers
    â”‚   â”‚  â”‚   â”‚â”€â”€ processing.py # Web endpoints for repetition counter and file download
    â”‚   â”‚  â”‚   â””â”€â”€ users.py # Web endpoints for user management
    â”‚   â”‚  â”‚â”€â”€ services
    â”‚   â”‚  â”‚   â”‚â”€â”€ download_service.py # Web file download function
    â”‚   â”‚  â”‚   â””â”€â”€ user_service.py # User session management functions
    â”‚   â”‚  â”‚
    â”‚   â”‚  â”œâ”€â”€ config.py # Backend web configuration parameters
    â”‚   â”‚  â”œâ”€â”€ main.py # Backend web startup and shutdown configuration
    â”‚   â”‚  â””â”€â”€ utils.py # Backend web utility functions (temporary file cleanup)
    â”‚   â””â”€â”€ data # Web API database
    â”‚
    â”œâ”€â”€ frontend_repCount
    â”‚   â””â”€â”€ src
    â”‚       â”œâ”€â”€ assets # Default images to display on the web API
    â”‚       â”œâ”€â”€ App.tsx/css # Index page
    â”‚       â”œâ”€â”€ History.tsx/css # User usage history page
    â”‚       â”œâ”€â”€ Login.tsx # User login page
    â”‚       â”œâ”€â”€ main.tsx # Initial rendering page
    â”‚       â”œâ”€â”€ Register.tsx # User registration page
    â”‚       â”œâ”€â”€ User.css # User pages style configuration
    â”‚       â”œâ”€â”€ UserProfile.tsx # User data page
    â”‚       â””â”€â”€ RepCount.tsx # Main page for repetition counter
    â”‚
    â”œâ”€â”€ functions # Utility functions for managing directories and datasets
    â”‚
    â”œâ”€â”€ Homography
    â”‚   â”œâ”€â”€ affine_2D_mod.py # (Unused) Keypoint correspondence transformation for image displacement, adapted for web API
    â”‚   â”œâ”€â”€ affine_2D.py # (Unused) Video transformation for keypoint correspondence by image displacement
    â”‚   â”œâ”€â”€ homography.py # Video transformation for keypoint correspondence by homography, adapted for web API
    â”‚   â””â”€â”€ homography_mod.py # Keypoint correspondence transformation by homography, adapted for web API
    â”‚
    â”œâ”€â”€ LSTM
    â”‚   â”œâ”€â”€ predict_LSTM.py # Script to infer on a directory with LSTM exercise classifier
    â”‚   â”œâ”€â”€ predict_LSTM_mod.py # Script for automatic inference with LSTM classifier on each execution from the web API
    â”‚   â””â”€â”€ predict_LSTM.py # LSTM classifier training script
    â”‚
    â”œâ”€â”€ repCount
    â”‚   â”œâ”€â”€ repCount_Sapiens.py # Full pipeline execution script on a video using poses inferred by Sapiens model
    â”‚   â”œâ”€â”€ repCount_YOLO11.py # Full pipeline execution script on a video using poses inferred by YOLO11pose model
    â”‚   â””â”€â”€ repCount_YOLO11_web.py # Full pipeline execution script from the web API using poses inferred by YOLO11pose model
    â”‚
    â”œâ”€â”€ Sapiens_Pose
    â”‚   â”œâ”€â”€ predict_pose.sh # Script to infer with Sapiens and build LSTM dataset
    â”‚   â””â”€â”€ keypoint_guide.txt # Sapiens keypoint index guide (COCO 17 format)
    â”‚
    â”œâ”€â”€ YOLO_pose
    â”‚   â”œâ”€â”€ predict_YOLO11_pose.py # Code to infer on an image directory with YOLO11seg
    â”‚   â””â”€â”€ predict_YOLO11_mod.py # Code for automatic inference with YOLO11seg on each execution from the web API
    â”‚
    â””â”€â”€ YOLO11seg
        â”œâ”€â”€ YOLO11seg_predict_exercise.py # Code to infer with YOLO11seg
        â””â”€â”€ YOLO11seg_train_eval_exercise.py # Code to train YOLO11seg


```

Joan Lara Formoso - Autonomous University of Barcelona
